# VoiceScreen AI - Autonomous Interview Agent

## Overview
VoiceScreen AI is an autonomous interview backend service that conducts structured AI-led interviews, evaluates candidates, and generates comprehensive reports with hiring recommendations.

## Features
- ‚úÖ AI-driven interview flow with state management
- ‚úÖ Dynamic question generation using Groq LLM
- ‚úÖ Real-time answer evaluation
- ‚úÖ Signal processing (talk ratio, sentiment, response quality)
- ‚úÖ Executive summary with PROCEED/HOLD/REJECT recommendation
- ‚úÖ Mock ATS integration
- ‚úÖ Full transcript and report generation

## Tech Stack
- **Framework**: FastAPI
- **Database**: Supabase (PostgreSQL)
- **LLM**: Groq (Llama 3.3)
- **State Management**: LangGraph (State Machine)
- **Validation**: Pydantic

## Setup Instructions

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure Environment Variables
Create a `.env` file in the root directory:
```env
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_anon_key
GROQ_API_KEY=your_groq_api_key
```

### 3. Database Setup
Ensure your Supabase project is active. Then, go to the **SQL Editor** in Supabase dashboard and execute the migration scripts located in `src/db/migrations/`:

**Order of execution:**
1. `src/db/migrations/001_add_constraints.sql` (Creates constraints)
2. `src/db/migrations/002_fix_status_constraint.sql` (Fixes 500 error for status)

Base tables required:
- `interview_sessions`
- `interview_turns`
- `interview_scores`
- `interview_signals`
- `ats_sync_logs`

### 4. Run the Backend Server
```bash
python run.py
```

**Alternative methods:**
```bash
# Method 1: Using uvicorn directly (recommended)
uvicorn src.main:app --host 0.0.0.0 --port 8080 --reload

# Method 2: Python module
python -m uvicorn src.main:app --host 0.0.0.0 --port 8080
```

The backend server will start on `http://localhost:8080`

### 5. Run the Frontend (Optional)
```bash
python run_frontend.py
```

Or directly:
```bash
streamlit run frontend_app.py
```

The Streamlit frontend will open at `http://localhost:8501`

**Features:**
- üéôÔ∏è Interactive interview interface
- üìã Real-time status tracking
- üí¨ Q&A flow with history
- üìä Results dashboard with scores
- üéØ Recommendation display

## API Documentation

### Base URL
```
http://localhost:8080
```

### Endpoints

#### 1. Create Interview
```http
POST /hr/interview/create
```
**Request:**
```json
{
  "candidateId": "CAND-001",
  "jobId": "JOB-101",
  "channel": "simulation",
  "consentRequired": true
}
```

#### 2. Get Disclosure
```http
GET /hr/interview/{interviewId}/disclosure
```

#### 3. Submit Consent
```http
POST /hr/interview/{interviewId}/consent
```
**Request:**
```json
{
  "consent": "yes"
}
```

#### 4. Get Next Question
```http
GET /hr/interview/{interviewId}/next-question
```

#### 5. Submit Answer
```http
POST /hr/interview/{interviewId}/answer
```
**Request:**
```json
{
  "turnNo": 1,
  "answer": "I once worked with..."
}
```

#### 6. Finish Interview
```http
POST /hr/interview/{interviewId}/finish
```

#### 7. Get Report
```http
GET /hr/interview/{interviewId}/report
```

## Testing with Postman/cURL

### Complete Interview Flow

1. **Create Interview**
```bash
curl -X POST http://localhost:8080/hr/interview/create \
  -H "Content-Type: application/json" \
  -d '{
    "candidateId": "CAND-001",
    "jobId": "JOB-101",
    "channel": "simulation",
    "consentRequired": true
  }'
```

2. **Get Disclosure**
```bash
curl http://localhost:8080/hr/interview/INT-{timestamp}/disclosure
```

3. **Submit Consent**
```bash
curl -X POST http://localhost:8080/hr/interview/INT-{timestamp}/consent \
  -H "Content-Type: application/json" \
  -d '{"consent": "yes"}'
```

4. **Get Question & Answer (Repeat 5-10 times)**
```bash
# Get question
curl http://localhost:8080/hr/interview/INT-{timestamp}/next-question

# Submit answer
curl -X POST http://localhost:8080/hr/interview/INT-{timestamp}/answer \
  -H "Content-Type: application/json" \
  -d '{
    "turnNo": 1,
    "answer": "Your answer here"
  }'
```

5. **Finish Interview**
```bash
curl -X POST http://localhost:8080/hr/interview/INT-{timestamp}/finish
```

6. **Get Report**
```bash
curl http://localhost:8080/hr/interview/INT-{timestamp}/report
```

## Interview Flow States

```
CREATED ‚Üí DISCLOSURE_DONE ‚Üí CONSENT_GRANTED ‚Üí INTERVIEW_IN_PROGRESS ‚Üí COMPLETED ‚Üí SYNCED_TO_ATS
```

## Scoring Logic

### Recommendation Rules
- **PROCEED**: overall ‚â• 75 AND no red flags AND consent granted
- **HOLD**: overall 60-74 OR missing 1 must-have skill
- **REJECT**: overall < 60 OR major red flags

### Evaluation Criteria
- Technical (0-100): Correctness and depth of technical answers
- Communication (0-100): Clarity, structure, articulation
- Culture (0-100): Confidence, ownership, team fit

## Project Structure
```
src/
  ‚îú‚îÄ‚îÄ main.py                          # FastAPI entry point
  ‚îú‚îÄ‚îÄ config.py                        # Configuration
  ‚îú‚îÄ‚îÄ routes/
  ‚îÇ   ‚îî‚îÄ‚îÄ interview_routes.py          # API routes
  ‚îú‚îÄ‚îÄ controllers/
  ‚îÇ   ‚îî‚îÄ‚îÄ interview_controller.py      # Business logic
  ‚îú‚îÄ‚îÄ services/
  ‚îÇ   ‚îú‚îÄ‚îÄ session_service.py           # Session management
  ‚îÇ   ‚îú‚îÄ‚îÄ question_service.py          # Question handling
  ‚îÇ   ‚îú‚îÄ‚îÄ scoring_service.py           # Scoring logic
  ‚îÇ   ‚îú‚îÄ‚îÄ signals_service.py           # Signal processing
  ‚îÇ   ‚îú‚îÄ‚îÄ summary_service.py           # Summary generation
  ‚îÇ   ‚îú‚îÄ‚îÄ ats_sync_service.py          # ATS integration
  ‚îÇ   ‚îî‚îÄ‚îÄ compliance_service.py        # Consent/Disclosure
  ‚îú‚îÄ‚îÄ agents/
  ‚îÇ   ‚îú‚îÄ‚îÄ question_generator_agent.py  # LLM question generation
  ‚îÇ   ‚îî‚îÄ‚îÄ evaluator_agent.py           # LLM evaluation
  ‚îú‚îÄ‚îÄ db/
  ‚îÇ   ‚îî‚îÄ‚îÄ supabase_client.py           # Database client
  ‚îî‚îÄ‚îÄ schemas/
      ‚îî‚îÄ‚îÄ interview_schema.py          # Pydantic models
```

## License
MIT
